{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vmb0gmB9Sv4F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\anaconda3\\envs\\DLassignment2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mAKXPzmTUMiE"
   },
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(r'D:\\NLP_Assignments\\23I-8038_NLP_A4\\Text Summarization Data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X615Ak5fUMkX",
    "outputId": "a6e3dd43-1f87-40c5-be90-8da50e2c9461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "Index(['id', 'article', 'highlights'], dtype='object')\n",
      "\n",
      "Number of features (columns): 3\n"
     ]
    }
   ],
   "source": [
    "# Display column names and number of features\n",
    "print(\"Columns in the dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nNumber of features (columns):\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VL_w8AXFUMnm"
   },
   "outputs": [],
   "source": [
    "# We only need the 'article' and 'highlights' columns\n",
    "df = df[['article', 'highlights']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DTNhVtKVUMpk"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing data\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oX016VYVUMtK"
   },
   "outputs": [],
   "source": [
    "# Reset index after dropping rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ft6k0e12Uayx",
    "outputId": "d75c8d20-56ff-490d-df84-8d4be4b27ba2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13368, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "i9liixBOUdcB"
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'article': 'text', 'highlights': 'summary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "N237DlF-Ufs4",
    "outputId": "58f34062-a8ba-4933-e6d2-a9a79b05c252"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sally Forrest, an actress-dancer who graced th...</td>\n",
       "      <td>Sally Forrest, an actress-dancer who graced th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A middle-school teacher in China has inked hun...</td>\n",
       "      <td>Works include pictures of Presidential Palace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man convicted of killing the father and sist...</td>\n",
       "      <td>Iftekhar Murtaza, 29, was convicted a year ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avid rugby fan Prince Harry could barely watch...</td>\n",
       "      <td>Prince Harry in attendance for England's crunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Triple M Radio producer has been inundated w...</td>\n",
       "      <td>Nick Slater's colleagues uploaded a picture to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Sally Forrest, an actress-dancer who graced th...   \n",
       "1  A middle-school teacher in China has inked hun...   \n",
       "2  A man convicted of killing the father and sist...   \n",
       "3  Avid rugby fan Prince Harry could barely watch...   \n",
       "4  A Triple M Radio producer has been inundated w...   \n",
       "\n",
       "                                             summary  \n",
       "0  Sally Forrest, an actress-dancer who graced th...  \n",
       "1  Works include pictures of Presidential Palace ...  \n",
       "2  Iftekhar Murtaza, 29, was convicted a year ago...  \n",
       "3  Prince Harry in attendance for England's crunc...  \n",
       "4  Nick Slater's colleagues uploaded a picture to...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EL09M4KPUiUg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer and Model setup\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "F7bAt2A1Uk9E"
   },
   "outputs": [],
   "source": [
    "# Freeze encoder layers for faster training\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jF2RH-KrUq1U"
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize_data(df, max_input_length=256, max_target_length=64):\n",
    "    inputs = tokenizer(df['text'].tolist(), padding=True, truncation=True, max_length=max_input_length, return_tensors='pt')\n",
    "    targets = tokenizer(df['summary'].tolist(), padding=True, truncation=True, max_length=max_target_length, return_tensors='pt')\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMJmS2MEUq3i"
   },
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FA306iKCUq7C"
   },
   "outputs": [],
   "source": [
    "train_inputs, train_targets = tokenize_data(train_df)\n",
    "val_inputs, val_targets = tokenize_data(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JScj24-6ZRsE"
   },
   "outputs": [],
   "source": [
    "# Custom dataset class for PyTorch DataLoader\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs['input_ids'][idx],\n",
    "            'attention_mask': self.inputs['attention_mask'][idx],\n",
    "            'labels': self.targets['input_ids'][idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "krX2Q2I8ZUml"
   },
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_dataset = SummarizationDataset(train_inputs, train_targets)\n",
    "val_dataset = SummarizationDataset(val_inputs, val_targets)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtAgIqS6U2PT",
    "outputId": "f5aec106-2436-41ec-bf42-73b3eb5aca7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\anaconda3\\envs\\DLassignment2\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10, \n",
    "    weight_decay=0.01,\n",
    "    fp16=True,  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "n3VkviTPZlQb",
    "outputId": "e73b66d3-13ef-406e-b7db-e535e97b61e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30080' max='30080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30080/30080 35:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.078600</td>\n",
       "      <td>1.859972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.029000</td>\n",
       "      <td>1.845963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.977800</td>\n",
       "      <td>1.844048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.942200</td>\n",
       "      <td>1.839024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.958100</td>\n",
       "      <td>1.834136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.956600</td>\n",
       "      <td>1.829594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.915000</td>\n",
       "      <td>1.833622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.912000</td>\n",
       "      <td>1.833661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.884800</td>\n",
       "      <td>1.833395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.893600</td>\n",
       "      <td>1.831903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30080, training_loss=1.947475141667305, metrics={'train_runtime': 2157.72, 'train_samples_per_second': 55.758, 'train_steps_per_second': 13.941, 'total_flos': 8141486067548160.0, 'train_loss': 1.947475141667305, 'epoch': 10.0})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "keCYvmrMVCsR",
    "outputId": "e7015805-b47c-4dcd-b900-e2ffa1e65c01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_t5/tokenizer_config.json',\n",
       " './fine_tuned_t5/special_tokens_map.json',\n",
       " './fine_tuned_t5/spiece.model',\n",
       " './fine_tuned_t5/added_tokens.json')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./fine_tuned_t5')\n",
    "tokenizer.save_pretrained('./fine_tuned_t5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "HecHYcs-mzqq"
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('./fine_tuned_t5')\n",
    "tokenizer = T5Tokenizer.from_pretrained('./fine_tuned_t5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVtYzc-BmvOq",
    "outputId": "598aaa4d-341a-4f48-d6fc-2c1eb14ca1a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "Machine learning is a branch of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. \n",
      "It involves the use of algorithms and statistical models to analyze patterns in data and make predictions or decisions without being explicitly programmed. \n",
      "Machine learning has become a significant area of research and application across various industries, from healthcare to finance, enabling systems to improve their performance over time through experience. \n",
      "The primary goal of machine learning is to develop algorithms that can generalize from previous observations, allowing them to perform well on unseen data.\n",
      "\n",
      "\n",
      "Summary:\n",
      "Machine learning is a branch of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. It involves the use of algorithms and statistical models to analyze patterns in data and make predictions or decisions without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to summarize text\n",
    "def summarize_text(text, max_length=150, num_beams=4):\n",
    "    # Preprocess the input text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate the summary with beam search\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, num_beams=num_beams, early_stopping=True)\n",
    "\n",
    "    # Decode the generated summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Example input text (you can replace it with your own)\n",
    "input_text = \"\"\"\n",
    "Machine learning is a branch of artificial intelligence that focuses on building systems that can learn from and make decisions based on data.\n",
    "It involves the use of algorithms and statistical models to analyze patterns in data and make predictions or decisions without being explicitly programmed.\n",
    "Machine learning has become a significant area of research and application across various industries, from healthcare to finance, enabling systems to improve their performance over time through experience.\n",
    "The primary goal of machine learning is to develop algorithms that can generalize from previous observations, allowing them to perform well on unseen data.\n",
    "\"\"\"\n",
    "\n",
    "# Get the summary\n",
    "summary = summarize_text(input_text)\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(input_text)\n",
    "print(\"\\nSummary:\")\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DLassignment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
